---
title: "План"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Вступ

Основний інструмент роботи: R. Перевага використання саме програмування для отримання інформації з веб-сторінок у дешевизні та гнучкості інструменту. Ви зможете пристосувати його під будь-яку задачу, яка стосується отримання інформації з веб-сторінок.

В цьому курсі мова буде йти про способи отримання інформації з веб-сторінок. Загалом є два основних механізми: 

* робота з Web API
* парсинг

Оскільки мова йде про отримання і поальше зберігання даних, то вступне заняття буде у великій мірі присвячено форматам даних в R.

Працювати ми будемо з такими форматами даних:

* vector
* data_frame
* list

Крім цього, розглянемо, як обробити в R файл у форматі json.

## Робота з Web API

Зміст: бібліотека httr та методи POST і GET

Практична користь: як отримати стандартизовані дані з бази веб-сторінки.

### Як працювати з будь-яким API

Зміст: алгоритм написання функції для отримання інформації з будь-якого сайту, у якого є API.

Практична користь: виникає проблема отримання даних із сайту, у якого є API, але нема готового інструменту взаємодії з ним в R. Як самому за короткий строк це зробити?

### Web API Facebook

Зміст: робота з бібліотекою Rfacebook

Практична користь: найшвидший спосіб отримати великий масив даних інформації з публічних сторінок та груп Facebook. Однак він не діє для персональних сторінок.

### API Twitter & VK

Зміст:

Практична користь:

## Парсинг

Зміст:

Практична користь: коли в сайту нема API або API віддає замало інформації іншого способу немає.

### Імітація роботи браузера в RSelenium

Зміст: можливості імітації роботи користувача в браузері через створення Selenium Driver.

Практична користь: найкращий спосіб отримувати дані з веб-сторінок, які вимагають взаємодії з користувачем (авторизація, навігація сторінками).

### Швидка обробка веб-сторінок у бібліотеці rvest

Зміст: бібліотека rvest і філософія набору пакетів tidyverse. Економний режим парсингу веб-сторінок.

Практична користь: ці бібліотеки дозволяють парсити веб-сторінки з мінімальним навантаженням на оперативну пам'ять та процесор. Дуже корисно при великих обсягах викачування.

### Парсинг новин в readability

Зміст: інтеграція можливостей Python в R на прикладі швидкого парсингу тексту новин у пакеті readability

Практична користь: дуже простий спосіб отримати текст веб-сторінки, який не вимагає вивчення її структури.
```{r, eval=FALSE}
library(xml2)
library(httr)
library(reticulate)
library(magrittr)

res <- GET("https://hmarochos.kiev.ua/2017/09/06/kvartirne-pitannya-chi-legko-orenduvati-zhitlo-u-kiyevi/")

readability <- import("readability") # pip install readability-lxml

doc <- readability$Document(httr::content(res, as="text", endoding="UTF-8"))

doc$summary() %>%
  read_xml() %>%
  xml_text() %>% cat()
```
